<html>
  <head>
    <title>chapter-2</title>
    
    <link rel="stylesheet" type="text/css" href="./chapter.css" > </link>
  </head>
  
  
  <body>
    <h1>渲染流程</h1>
    <p class="sub_title">——致虚极，守笃静，万物并作，吾以观复/p>
    
    <p>
      WebGL依赖GPU的图形渲染能力，即依赖硬件设备，所以其渲染流程和GPU内部的渲染管线是相符的。渲染管线的作用是将3D模型转换为2维图像。
    </p>
    <p>
      早期的渲染管线是不可编程的，叫做固定渲染管线，现代的GPU所包含的渲染管线为可编程渲染管线。本节所述皆基于可渲染管线
    </p>  
    <p class="comment inner_para">
      两种渲染管线的区别简单可以理解为前者工作的细节流程已经固定，只需要调整一些参数，后者更具灵活性，可以通过编程（GLSL，graphic language shader language）来控制一些渲染阶段的细节，现代的GPU已经不支持固定渲染管线了。
    </p>
    <p class="comment inner_para">
      Modern GPUs no longer provide specialized hardware for the purpose of doing specific calculations in the OpenGL pipeline. Everything is done with shaders. In order to preserve compatibility, the GL driver generates a shader which emulates the fixed functionality.
    </p>
    
    <p class="comment inner_para">
      Among many others, a simple example is rendering a primitive using one function call to submit each vertex attribute separately, e.g. glVertex3f(1.f, 0.f, 0.f), inside a glBegin() and glEnd() statement. 
    </p>
    <br>
    <br>
    
    <p class="inner_para">
      渲染模拟的是人眼对于立体模型的成像过程，因此渲染的方法需要从真实世界中寻找答案，下面先思考三个问题：
    </p>
      <p class="inner_para no_indent text_block1">1、怎么描述一个空间面（三个点确定一个面，另外加上颜色）；</p>
      <p class="inner_para no_indent text_block1">2、立体空间中，人眼中的正方体是什么样子的？（近大远小、近处遮蔽远处）</p>
      <p class="inner_para no_indent text_block1">3、如果把人眼看到东西放在屏幕上怎么做？（屏幕是由像素组成的）</p>
    
    <br>
    <br>
    
    <p class="key_words">
      下面假设存在三个顶点A、B、C，组成三角形通过下面的渲染过程。
    </p>
    
    <h2>顶点着色（vertex shader）</h2>
    <p class="inner_para">
      顶点着色阶段的作用是通过计算最终的顶点坐标，过程如下描述：
    </p>
    
    <p>
      A顶点通过此阶段坐标发生变动，因而A变为了顶点A1，B变为了B1，C变为了C1。然后A1，B1，C1转到下个着色阶段。暂时不考虑怎么从A变动到A1
    </p>

    <h2>图元装配</h2>
      <p>把顶点组成图元，webgl内的图元有三角型、线、点，常用的是三角形图元。后面的处理需要把图元这一处理单元，过程如下描述：</p>
      <p>假设我们选择的图元是三角形， 那么A1，B1，C1在此被组织为一个三角形，此时已经A1、B1、C1已经不再是独立战斗的个体，而是一个team。组成的三角形传入后面阶段。</p>
    
    <h2>裁剪</h2>
      <p>把坐标的x、y、z分量不全在（-1,1）区间内的图元（或者图元的部分）抛弃掉，过程如下描述：</p>
      <p>假设三角形有一个顶点C1坐标的任意一维在区间（-1,1），也就是三角形不全在区间（-1,1）内，那么进行裁剪，裁剪完的图形记为P，传入下个阶段。</p>
    
    <h2>光栅化</h2>
    <p>
      三维转换为二维的过程通过此过程完成。简单的可以想象为把三维图形沿着平行于z轴的方向压扁，然后得到二维的图形，然后映射到屏幕大小，生成一个个的像素大小的片元。由于场景可能相当复杂，所以可能同一个屏幕像素对应的地方同时存在多个深度不同的片元，过程如下描述：
    </p>
    <p> 
      把一个x和y值域在（-1， 1）的面映射到显示渲染结果的画布（简单理解为屏幕）那么大， 然后先不考虑组成图形P的顶点的z坐标，把P画在值域在（-1， 1）的面上，那么P覆盖的屏幕像素即在图形P内，P内的像素就是一个一个的片元了，然后每个片元分别通过下个阶段。
    </p>
    <div class="img_wrapper"><img src="./resources/rasterization.png"><br>光栅化</img></div>
  
  
    <h2>片元着色（vertex shader）</h2>
    <p>
      接收光栅化阶段生成的片元，每个片元都有一个颜色缓存，保存片元的颜色，暂时先不管颜色是怎么生成的。此阶段处理过的片元会继续向后面的阶段传递
    </p>

    <h2>逐片元挑选</h2>
    <p>
      此部分可以抛弃部分片元，生成屏幕上最终显示的图像，这种抛弃部分片元的操作可以通过模板测试和深度测试来完成。至此2D图像已经确定，接下来GPU将图像显示在屏幕上就可以了。
    </p>
    <p class="inner_para">
      深度测试，还记得前面顶点着色阶段计算出的坐标的z分量吗，这个就是片元的深度。还回到之前的我们的三角形绘制，GPU为画布初始化的缓存的颜色是黑色的，深度是1，我们认定z值较小的片元离眼睛更近，那么对片元着色传来的片元的深度（z值）与GPU缓存中的做比较，z值小的片元的则覆盖GPU缓存对应的像素的颜色和z值，那么我们的三角形（假设顶点着色计算出来的顶点z值都比1小）就保留在GPU的缓存中了。
    </p>
    <p class="inner_para">
      如法炮制，我们按照之前的渲染过程再画一个三角形，还是保留z值小的片元。完整的场景是由复杂的面组成的，面都可以通过细分变为小的三角形，通过此种方法就能实现近的遮蔽远处物体的效果。
    </p>
    <br>
    <br>
    <p class="inner_para">
      模板测试，简单的一个应用是做一个镜子。实现镜子的效果需要在镜子中反射其他的物体，要做到这个效果，需要把镜子所在的区域进行标记，使得反射的图像只绘制在有标记的区域。
    </p>
    
    <br>
    <br>
    
    <h2>再看顶点着色过程</h2>
      <p class="inner_para">
        这里将对顶点坐标的计算过程进行展开，顶点坐标计算过程就是改变顶点的坐标信息，当然原始输入的也可以是最终的顶点，即顶点不发生变化。
      </p>
      <p  class="inner_para">
        这个过程可以控制物体位置的变化和缩放；
      </p>
      <p  class="inner_para">
        还可以通过透视投影模拟人眼成像，产生近大远小的效果。透视投影的结果是对也是对顶点坐标进行改变，透视投影描述了一个椎体，如下图所示，存在近裁面(离摄像头进的位置)和远裁面，落在此椎体内的顶点通过投影计算得到的顶点坐标才在（-1， 1）的区间之内，即能够在 裁剪阶段保留下来。
      </p>
      <div class="img_wrapper"><img src="./resources/projective.jpg"><br>透视投影</img></div>
      
      <br>
      <p>
        除了顶点坐标的计算之外，还有一点需要提及的是顶点着色阶段时传入不仅有顶点的坐标数据，还可以附带诸如颜色之类的顶点数据，这些数据如果需要向后面的阶段传递（简单的理解为向传递到片元着色阶段），那么光栅化阶段在生成片元时，会将这些数据做差值计算，使得每个片元都携带顶点的信息！
      </p>
    
    
    <p class="comment">
      本节所讲的是基于光栅化的渲染，还有一种是基于光线追踪技术；前者等于是先确定物体上每个点的颜色，然后压成一个平面，后者是基于“能够看到一个物体是由于看到它发出的光”的物理原理，即从通过跟踪光源发出的每条光线，然后根据人眼（摄像机）能够捕捉到的光线进行成像，因此后者更为接近真实，但是同时带来了高计算量的问题，所以不能应用于实时渲染过程。
    </p>
    
    <br>
    <br>
  </body>
</html>